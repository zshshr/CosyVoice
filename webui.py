# Copyright (c) 2024 Alibaba Inc (authors: Xiang Lyu, Liu Yue)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import os
import sys
import argparse
import gradio as gr
import numpy as np
import torch
import torchaudio
import random
import librosa
import logging
import platform
import psutil
import GPUtil
import onnxruntime as ort
import threading
import time


# ä»…åšæ—¥å¿—æç¤ºï¼Œä¸è°ƒç”¨ set_default_providers
if 'CUDAExecutionProvider' in ort.get_available_providers():
    logging.info("Using CUDA for onnxruntime")
    # æ·»åŠ  onnxruntime ä¼˜åŒ–é€‰é¡¹
    session_options = ort.SessionOptions()
    session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
    session_options.enable_mem_pattern = True
    session_options.enable_cpu_mem_arena = True
    session_options.log_severity_level = 1
else:
    logging.warning("CUDA not available for onnxruntime, using CPU")
    session_options = ort.SessionOptions()
    session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
    session_options.enable_mem_pattern = True
    session_options.enable_cpu_mem_arena = True
    session_options.log_severity_level = 1

ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append('{}/third_party/Matcha-TTS'.format(ROOT_DIR))

# æ£€æŸ¥ ttsfrd æ˜¯å¦å¯ç”¨
try:
    import ttsfrd
    TTSFRD_AVAILABLE = True
except ImportError:
    TTSFRD_AVAILABLE = False
    logging.warning("ttsfrd package not available, using WeTextProcessing instead")

from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2
from cosyvoice.utils.file_utils import load_wav
from cosyvoice.utils.common import set_all_random_seed

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO,
                   format='%(asctime)s - %(levelname)s - %(message)s')

# æ¨¡å‹é…ç½®
AVAILABLE_MODELS = {
    'CosyVoice-300M': 'pretrained_models/CosyVoice-300M',
    'CosyVoice-300M-SFT': 'pretrained_models/CosyVoice-300M-SFT',
    'CosyVoice-300M-Instruct': 'pretrained_models/CosyVoice-300M-Instruct',
    'CosyVoice2-0.5B': 'pretrained_models/CosyVoice2-0.5B'
}

inference_mode_list = ['é¢„è®­ç»ƒéŸ³è‰²', '3sæé€Ÿå¤åˆ»', 'è·¨è¯­ç§å¤åˆ»', 'è‡ªç„¶è¯­è¨€æ§åˆ¶']
instruct_dict = {'é¢„è®­ç»ƒéŸ³è‰²': '1. é€‰æ‹©é¢„è®­ç»ƒéŸ³è‰²\n2. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®',
                 '3sæé€Ÿå¤åˆ»': '1. é€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶ï¼Œæˆ–å½•å…¥promptéŸ³é¢‘ï¼Œæ³¨æ„ä¸è¶…è¿‡30sï¼Œè‹¥åŒæ—¶æä¾›ï¼Œä¼˜å…ˆé€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶\n2. è¾“å…¥promptæ–‡æœ¬\n3. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®',
                 'è·¨è¯­ç§å¤åˆ»': '1. é€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶ï¼Œæˆ–å½•å…¥promptéŸ³é¢‘ï¼Œæ³¨æ„ä¸è¶…è¿‡30sï¼Œè‹¥åŒæ—¶æä¾›ï¼Œä¼˜å…ˆé€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶\n2. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®',
                 'è‡ªç„¶è¯­è¨€æ§åˆ¶': '1. é€‰æ‹©é¢„è®­ç»ƒéŸ³è‰²\n2. è¾“å…¥instructæ–‡æœ¬\n3. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®'}
stream_mode_list = [('å¦', False), ('æ˜¯', True)]
max_val = 0.8

def check_ttsfrd_installation():
    """æ£€æŸ¥ ttsfrd å®‰è£…çŠ¶æ€å¹¶æä¾›å»ºè®®"""
    if not TTSFRD_AVAILABLE:
        system = platform.system()
        if system == "Windows":
            return """
            ttsfrd åŒ…æœªå®‰è£…æˆ–ä¸å¯ç”¨ã€‚å½“å‰ç³»ç»Ÿä¸º Windowsï¼Œä½†æä¾›çš„ ttsfrd wheel æ–‡ä»¶ä»…æ”¯æŒ Linuxã€‚
            ç³»ç»Ÿå°†ä½¿ç”¨ WeTextProcessing ä½œä¸ºæ›¿ä»£ã€‚
            
            æ³¨æ„ï¼šè¿™ä¸ä¼šå½±å“åŸºæœ¬åŠŸèƒ½ï¼Œä½†å¯èƒ½ä¼šå½±å“æŸäº›æ–‡æœ¬å¤„ç†ç‰¹æ€§ã€‚
            """
        else:
            return """
            ttsfrd åŒ…æœªå®‰è£…ã€‚è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š
            pip install pretrained_models/CosyVoice-ttsfrd/ttsfrd_dependency-0.1-py3-none-any.whl
            pip install pretrained_models/CosyVoice-ttsfrd/ttsfrd-0.4.2-cp310-cp310-linux_x86_64.whl
            """
    return "ttsfrd åŒ…å·²æ­£ç¡®å®‰è£…"

def load_model(model_name):
    """åŠ è½½æŒ‡å®šçš„æ¨¡å‹"""
    model_path = AVAILABLE_MODELS.get(model_name)
    if not model_path:
        return None, "æ¨¡å‹ä¸å­˜åœ¨"
    
    if not os.path.exists(model_path):
        return None, f"æ¨¡å‹ç›®å½• {model_path} ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½æ¨¡å‹"
    
    try:
        logging.info(f"Attempting to load model from {model_path}")
        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©åŠ è½½æ–¹å¼
        if model_name == 'CosyVoice2-0.5B':
            model = CosyVoice2(model_path, load_jit=False, load_trt=False, fp16=False, use_flow_cache=True)
        else:
            model = CosyVoice(model_path, load_jit=False, load_trt=False, fp16=False)
        
        logging.info("Successfully loaded model")
        device_info = "CPU" if not torch.cuda.is_available() else f"GPU ({torch.cuda.get_device_name(0)})"
        
        # è·å–é¢„è®­ç»ƒéŸ³è‰²åˆ—è¡¨
        spk_list = model.list_available_spks()
        logging.info(f"Available speakers: {spk_list}")
        
        return model, f"æ¨¡å‹åŠ è½½æˆåŠŸ (ä½¿ç”¨{device_info}è¿›è¡Œæ¨ç†)"
    except Exception as e:
        logging.error(f"Failed to load model: {str(e)}")
        error_msg = f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
        if "CUDA" in str(e):
            error_msg += "\næ³¨æ„ï¼šæœªæ£€æµ‹åˆ°CUDAæ”¯æŒï¼Œå°†ä½¿ç”¨CPUè¿›è¡Œæ¨ç†ï¼Œè¿™å¯èƒ½ä¼šå½±å“æ€§èƒ½"
        return None, error_msg

def generate_seed():
    seed = random.randint(1, 100000000)
    return {
        "__type__": "update",
        "value": seed
    }


def postprocess(speech, top_db=60, hop_length=220, win_length=440):
    speech, _ = librosa.effects.trim(
        speech, top_db=top_db,
        frame_length=win_length,
        hop_length=hop_length
    )
    if speech.abs().max() > max_val:
        speech = speech / speech.abs().max() * max_val
    speech = torch.concat([speech, torch.zeros(1, int(cosyvoice.sample_rate * 0.2))], dim=1)
    return speech


def change_instruction(mode_checkbox_group):
    return instruct_dict[mode_checkbox_group]


def generate_audio(tts_text, mode_checkbox_group, sft_dropdown, prompt_text, prompt_wav_upload, prompt_wav_record, instruct_text,
                   seed, stream, speed):
    global cosyvoice  # æ·»åŠ å…¨å±€å˜é‡å£°æ˜
    
    if current_model[0] is None:
        gr.Warning('è¯·å…ˆåŠ è½½æ¨¡å‹')
        return (16000, np.zeros(16000))
    
    cosyvoice = current_model[0]  # ä½¿ç”¨å½“å‰åŠ è½½çš„æ¨¡å‹
    
    if prompt_wav_upload is not None:
        prompt_wav = prompt_wav_upload
    elif prompt_wav_record is not None:
        prompt_wav = prompt_wav_record
    else:
        prompt_wav = None

    # æ£€æŸ¥è¾“å…¥å‚æ•°
    if not tts_text:
        gr.Warning('è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬')
        return (16000, np.zeros(16000))

    # if instruct mode, please make sure that model is iic/CosyVoice-300M-Instruct and not cross_lingual mode
    if mode_checkbox_group in ['è‡ªç„¶è¯­è¨€æ§åˆ¶']:
        if cosyvoice.instruct is False:
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼, {}æ¨¡å‹ä¸æ”¯æŒæ­¤æ¨¡å¼, è¯·ä½¿ç”¨iic/CosyVoice-300M-Instructæ¨¡å‹'.format(args.model_dir))
            return (16000, np.zeros(16000))
        if instruct_text == '':
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼, è¯·è¾“å…¥instructæ–‡æœ¬')
            return (16000, np.zeros(16000))
        if prompt_wav is not None or prompt_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼, promptéŸ³é¢‘/promptæ–‡æœ¬ä¼šè¢«å¿½ç•¥')

    # if cross_lingual mode, please make sure that model is iic/CosyVoice-300M and tts_text prompt_text are different language
    if mode_checkbox_group in ['è·¨è¯­ç§å¤åˆ»']:
        if cosyvoice.instruct is True:
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, {}æ¨¡å‹ä¸æ”¯æŒæ­¤æ¨¡å¼, è¯·ä½¿ç”¨iic/CosyVoice-300Mæ¨¡å‹'.format(args.model_dir))
            return (16000, np.zeros(16000))
        if instruct_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, instructæ–‡æœ¬ä¼šè¢«å¿½ç•¥')
        if prompt_wav is None:
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, è¯·æä¾›promptéŸ³é¢‘')
            return (16000, np.zeros(16000))
        gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, è¯·ç¡®ä¿åˆæˆæ–‡æœ¬å’Œpromptæ–‡æœ¬ä¸ºä¸åŒè¯­è¨€')

    # if in zero_shot cross_lingual, please make sure that prompt_text and prompt_wav meets requirements
    if mode_checkbox_group in ['3sæé€Ÿå¤åˆ»', 'è·¨è¯­ç§å¤åˆ»']:
        if prompt_wav is None:
            gr.Warning('promptéŸ³é¢‘ä¸ºç©ºï¼Œæ‚¨æ˜¯å¦å¿˜è®°è¾“å…¥promptéŸ³é¢‘ï¼Ÿ')
            return (16000, np.zeros(16000))
        if torchaudio.info(prompt_wav).sample_rate < prompt_sr:
            gr.Warning('promptéŸ³é¢‘é‡‡æ ·ç‡{}ä½äº{}'.format(torchaudio.info(prompt_wav).sample_rate, prompt_sr))
            return (16000, np.zeros(16000))

    # sft mode only use sft_dropdown
    if mode_checkbox_group in ['é¢„è®­ç»ƒéŸ³è‰²']:
        if instruct_text != '' or prompt_wav is not None or prompt_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨é¢„è®­ç»ƒéŸ³è‰²æ¨¡å¼ï¼Œpromptæ–‡æœ¬/promptéŸ³é¢‘/instructæ–‡æœ¬ä¼šè¢«å¿½ç•¥ï¼')
        if sft_dropdown == '':
            gr.Warning('æ²¡æœ‰å¯ç”¨çš„é¢„è®­ç»ƒéŸ³è‰²ï¼')
            return (16000, np.zeros(16000))

    # zero_shot mode only use prompt_wav prompt text
    if mode_checkbox_group in ['3sæé€Ÿå¤åˆ»']:
        if prompt_text == '':
            gr.Warning('promptæ–‡æœ¬ä¸ºç©ºï¼Œæ‚¨æ˜¯å¦å¿˜è®°è¾“å…¥promptæ–‡æœ¬ï¼Ÿ')
            return (16000, np.zeros(16000))
        if instruct_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨3sæé€Ÿå¤åˆ»æ¨¡å¼ï¼Œé¢„è®­ç»ƒéŸ³è‰²/instructæ–‡æœ¬ä¼šè¢«å¿½ç•¥ï¼')

    try:
        if mode_checkbox_group == 'é¢„è®­ç»ƒéŸ³è‰²':
            logging.info('get sft inference request')
            set_all_random_seed(seed)
            for i in cosyvoice.inference_sft(tts_text, sft_dropdown, stream=stream, speed=speed):
                yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
        elif mode_checkbox_group == '3sæé€Ÿå¤åˆ»':
            logging.info('get zero_shot inference request')
            prompt_speech_16k = postprocess(load_wav(prompt_wav, prompt_sr))
            set_all_random_seed(seed)
            for i in cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k, stream=stream, speed=speed):
                yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
        elif mode_checkbox_group == 'è·¨è¯­ç§å¤åˆ»':
            logging.info('get cross_lingual inference request')
            prompt_speech_16k = postprocess(load_wav(prompt_wav, prompt_sr))
            set_all_random_seed(seed)
            for i in cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k, stream=stream, speed=speed):
                yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
        else:
            logging.info('get instruct inference request')
            set_all_random_seed(seed)
            for i in cosyvoice.inference_instruct(tts_text, sft_dropdown, instruct_text, stream=stream, speed=speed):
                yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
    except Exception as e:
        logging.error(f"Error during audio generation: {str(e)}")
        gr.Error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
        return (16000, np.zeros(16000))

def get_system_info():
    """è·å–ç³»ç»Ÿç¡¬ä»¶ä¿¡æ¯"""
    info = []
    
    # CPUä¿¡æ¯
    cpu_info = f"CPU: {platform.processor()}"
    cpu_count = psutil.cpu_count(logical=False)
    cpu_logical = psutil.cpu_count(logical=True)
    cpu_info += f" ({cpu_count} ç‰©ç†æ ¸å¿ƒ, {cpu_logical} é€»è¾‘æ ¸å¿ƒ)"
    info.append(cpu_info)
    
    # å†…å­˜ä¿¡æ¯
    memory = psutil.virtual_memory()
    memory_info = f"å†…å­˜: {memory.total / (1024**3):.1f}GB (å¯ç”¨: {memory.available / (1024**3):.1f}GB)"
    info.append(memory_info)
    
    # CUDAä¿¡æ¯
    cuda_available = torch.cuda.is_available()
    if cuda_available:
        cuda_info = f"CUDA: å¯ç”¨ (ç‰ˆæœ¬ {torch.version.cuda})"
        gpu_info = []
        for i in range(torch.cuda.device_count()):
            gpu = GPUtil.getGPUs()[i]
            gpu_info.append(f"GPU {i}: {gpu.name} ({gpu.memoryTotal}MB)")
        info.append(cuda_info)
        info.extend(gpu_info)
    else:
        info.append("CUDA: ä¸å¯ç”¨ (å°†ä½¿ç”¨CPUè¿›è¡Œæ¨ç†)")
        info.append("æ³¨æ„ï¼šä½¿ç”¨CPUè¿›è¡Œæ¨ç†å¯èƒ½ä¼šå½±å“æ€§èƒ½")
    
    # æ“ä½œç³»ç»Ÿä¿¡æ¯
    system = platform.system()
    
    # æ£€æµ‹ Windows 11
    if system == "Windows":
        try:
            import winreg
            with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\Microsoft\Windows NT\CurrentVersion") as key:
                product_name = winreg.QueryValueEx(key, "ProductName")[0]
                build_number = winreg.QueryValueEx(key, "CurrentBuildNumber")[0]
                if "Windows 11" in product_name or int(build_number) >= 22000:
                    os_info = f"æ“ä½œç³»ç»Ÿ: Windows 11 (Build {build_number})"
                else:
                    os_info = f"æ“ä½œç³»ç»Ÿ: {product_name} (Build {build_number})"
        except:
            # å¦‚æœæ— æ³•è·å–è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨åŸºæœ¬ç³»ç»Ÿä¿¡æ¯
            os_info = f"æ“ä½œç³»ç»Ÿ: {system} {platform.release()}"
    else:
        os_info = f"æ“ä½œç³»ç»Ÿ: {system} {platform.release()}"
    
    info.append(os_info)
    
    return "\n".join(info)

def main():
    # å…¨å±€å˜é‡å£°æ˜
    global current_model, cosyvoice, prompt_sr
    current_model = [None]  # åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
    prompt_sr = 16000  # è®¾ç½®é‡‡æ ·ç‡

    # è¯»å–ä½¿ç”¨è¯´æ˜æ–‡æ¡£
    usage_guide = ""
    try:
        with open('USAGE.md', 'r', encoding='utf-8') as f:
            usage_guide = f.read()
    except Exception as e:
        logging.error(f"Failed to read USAGE.md: {str(e)}")
        usage_guide = "ä½¿ç”¨è¯´æ˜æ–‡æ¡£åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ USAGE.md æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚"

    with gr.Blocks() as demo:
        gr.Markdown("### CosyVoice è¯­éŸ³åˆæˆç³»ç»Ÿ")
        
        # ç³»ç»Ÿä¿¡æ¯æ˜¾ç¤º
        with gr.Accordion("ç³»ç»Ÿä¿¡æ¯", open=True):
            system_info = get_system_info()
            gr.Markdown(f"```\n{system_info}\n```")
        
        # ttsfrd çŠ¶æ€æ£€æŸ¥
        ttsfrd_status = check_ttsfrd_installation()
        if not TTSFRD_AVAILABLE:
            with gr.Accordion("âš ï¸ ç³»ç»Ÿæç¤º", open=True):
                gr.Markdown(ttsfrd_status)
        
        # æ¨¡å‹é€‰æ‹©å’ŒåŠ è½½éƒ¨åˆ†
        with gr.Row():
            model_dropdown = gr.Dropdown(
                choices=list(AVAILABLE_MODELS.keys()),
                label="é€‰æ‹©æ¨¡å‹",
                value=list(AVAILABLE_MODELS.keys())[0]
            )
            load_model_button = gr.Button("åŠ è½½æ¨¡å‹")
            model_status = gr.Textbox(label="æ¨¡å‹çŠ¶æ€", interactive=False)
    
        
        gr.Markdown("#### è¯·è¾“å…¥éœ€è¦åˆæˆçš„æ–‡æœ¬ï¼Œé€‰æ‹©æ¨ç†æ¨¡å¼ï¼Œå¹¶æŒ‰ç…§æç¤ºæ­¥éª¤è¿›è¡Œæ“ä½œ")

        tts_text = gr.Textbox(label="è¾“å…¥åˆæˆæ–‡æœ¬", lines=1, value="æˆ‘æ˜¯é€šä¹‰å®éªŒå®¤è¯­éŸ³å›¢é˜Ÿå…¨æ–°æ¨å‡ºçš„ç”Ÿæˆå¼è¯­éŸ³å¤§æ¨¡å‹ï¼Œæä¾›èˆ’é€‚è‡ªç„¶çš„è¯­éŸ³åˆæˆèƒ½åŠ›ã€‚")
        with gr.Row():
            mode_checkbox_group = gr.Radio(choices=inference_mode_list, label='é€‰æ‹©æ¨ç†æ¨¡å¼', value=inference_mode_list[0])
            instruction_text = gr.Text(label="æ“ä½œæ­¥éª¤", value=instruct_dict[inference_mode_list[0]], scale=2)
            sft_dropdown = gr.Dropdown(
                choices=[''],  # åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨ï¼Œä½†åŒ…å«ä¸€ä¸ªç©ºé€‰é¡¹
                label='é€‰æ‹©é¢„è®­ç»ƒéŸ³è‰²',
                value='',  # åˆå§‹å€¼è®¾ä¸ºç©ºå­—ç¬¦ä¸²
                scale=1
            )
            stream = gr.Radio(choices=stream_mode_list, label='æ˜¯å¦æµå¼æ¨ç†', value=stream_mode_list[0][1])
            speed = gr.Number(value=1, label="é€Ÿåº¦è°ƒèŠ‚(ä»…æ”¯æŒéæµå¼æ¨ç†)", minimum=0.5, maximum=2.0, step=0.1)
            with gr.Column(scale=1):
                seed_button = gr.Button(value="\U0001F3B2")
                seed = gr.Number(value=0, label="éšæœºæ¨ç†ç§å­")

        with gr.Row():
            prompt_wav_upload = gr.Audio(sources='upload', type='filepath', label='é€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶ï¼Œæ³¨æ„é‡‡æ ·ç‡ä¸ä½äº16khz')
            prompt_wav_record = gr.Audio(sources='microphone', type='filepath', label='å½•åˆ¶promptéŸ³é¢‘æ–‡ä»¶')
        prompt_text = gr.Textbox(label="è¾“å…¥promptæ–‡æœ¬", lines=1, placeholder="è¯·è¾“å…¥promptæ–‡æœ¬ï¼Œéœ€ä¸promptéŸ³é¢‘å†…å®¹ä¸€è‡´ï¼Œæš‚æ—¶ä¸æ”¯æŒè‡ªåŠ¨è¯†åˆ«...", value='')
        instruct_text = gr.Textbox(label="è¾“å…¥instructæ–‡æœ¬", lines=1, placeholder="è¯·è¾“å…¥instructæ–‡æœ¬.", value='')

        generate_button = gr.Button("ç”ŸæˆéŸ³é¢‘")
        audio_output = gr.Audio(label="åˆæˆéŸ³é¢‘", autoplay=True, streaming=True)

        def on_model_load(model_name):
            """å¤„ç†æ¨¡å‹åŠ è½½äº‹ä»¶"""
            try:
                model, status = load_model(model_name)
                if model is not None:
                    current_model[0] = model
                    # è·å–é¢„è®­ç»ƒéŸ³è‰²åˆ—è¡¨
                    spk_list = model.list_available_spks()
                    logging.info(f"Available speakers for {model_name}: {spk_list}")
                    
                    if not spk_list:
                        logging.warning(f"No speakers found for model {model_name}")
                        return status, gr.update(choices=[''], value='')
                    
                    return status, gr.update(choices=spk_list, value=spk_list[0])
                else:
                    current_model[0] = None
                    return status, gr.update(choices=[''], value='')
            except Exception as e:
                logging.error(f"Error in on_model_load: {str(e)}")
                return f"åŠ è½½æ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", gr.update(choices=[''], value='')

        def on_generate_audio(*args):
            if current_model[0] is None:
                gr.Warning('è¯·å…ˆåŠ è½½æ¨¡å‹')
                return (16000, np.zeros(16000))
            
            try:
                for audio in generate_audio(*args):
                    if isinstance(audio, tuple) and len(audio) == 2:
                        sample_rate, audio_data = audio
                        if isinstance(audio_data, np.ndarray):
                            return (sample_rate, audio_data)
                    return (16000, np.zeros(16000))
            except Exception as e:
                logging.error(f"Error during audio generation: {str(e)}")
                gr.Error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
                return (16000, np.zeros(16000))

        # åœ¨é¡µé¢åº•éƒ¨æ·»åŠ è¯¦ç»†ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown(usage_guide)

        # ç»‘å®šäº‹ä»¶
        load_model_button.click(
            on_model_load,
            inputs=[model_dropdown],
            outputs=[model_status, sft_dropdown]
        )
        
        seed_button.click(generate_seed, inputs=[], outputs=seed)
        generate_button.click(
            on_generate_audio,
            inputs=[tts_text, mode_checkbox_group, sft_dropdown, prompt_text, prompt_wav_upload, prompt_wav_record, instruct_text,
                    seed, stream, speed],
            outputs=[audio_output]
        )
        mode_checkbox_group.change(fn=change_instruction, inputs=[mode_checkbox_group], outputs=[instruction_text])

    # æ³¨é‡Šæ‰ queue ç›¸å…³ä»£ç 
    # demo.queue(max_size=4, default_concurrency_limit=2)
    
    # ç›´æ¥å¯åŠ¨ Gradioï¼Œä¸ä½¿ç”¨çº¿ç¨‹ï¼Œä½†å…è®¸åå°è¿è¡Œ
    demo.launch(
        server_name='127.0.0.1', 
        server_port=args.port, 
        inbrowser=False, 
        show_error=True,
        prevent_thread_lock=True  # æ·»åŠ è¿™ä¸ªå‚æ•°è®© Gradio åœ¨åå°è¿è¡Œ
    )

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--port', type=int, default=8000)
    args = parser.parse_args()

    # åœ¨ä¸»çº¿ç¨‹ä¸­å¯åŠ¨ Gradio
    main()

    # ç­‰å¾… Gradio æœåŠ¡å™¨å¯åŠ¨
    import requests
    import time
    for _ in range(30):
        try:
            r = requests.get(f"http://127.0.0.1:{args.port}")
            if r.status_code == 200:
                break
        except:
            time.sleep(1)

    # åœ¨ä¸»çº¿ç¨‹ä¸­å¯åŠ¨ webview
    import webview
    webview.create_window(
        "CosyVoice æ¡Œé¢ç‰ˆ", 
        f"http://127.0.0.1:{args.port}", 
        width=1280, 
        height=900, 
        resizable=True, 
        background_color="#f3f3f3"
    )
    webview.start()
